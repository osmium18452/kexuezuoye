In this section, we present the commonly used datasets and tool packages for causal inference experiments.

\subsection{Datasets}\label{subsec:datasets}

The available dataset for causal inference is summarized in this section.
It's hard to find a dataset with perfect ground truth for counterfactual experiment due to the fact that it is
impossible to observe counterfactual outcome.
Semi-synthetic datasets are often used in literature.
IHDP, for example, is obtained by generating its own observed outcome following some certain generating process.
The detailed description of these commonly used datasets are in the following.

\subsubsection{IHDP}.
This dataset is an often used dataset generated from the experiment conducted by Infant Health and Development
Program\cite{brooks1992effects} targeting on the premature infants with low birth-weight.
In the experiment, infants were subject to the control group and experiment group.
Infants in the control groups were care by their families while those in the experiment group received both high quality
childcare by specialists\cite{hill2011bayesian}.
The pre-treatment co-variates are composed by 25 variables measuring the infants' and their mothers' conditions,
including birth weight, head size, prenatal care, mothers' age, education, medical situation etc.
The outcome is these infants' cognitive test score.
To simulate the selection bias, a biased subset of the experiment group should be removed while using.

\subsubsection{Twins}.
The Twins dataset is generated from twin birth rates in the United States between 1989 and 1991\cite{almond2005costs}.
This dataset was proposed by C. Louizos et al.\ in~\cite{louizos2017causal}.
The treatment of the Twins dataset is being the heavier one of the two, and the outcome is the death rate of it in its
first year of life.
In this dataset, only 11,984 pairs of twins weighting less than 2kg and with the same gender were selected, since the
outcome was very rare (3.5\% in total).
The mortality rate of the selected infants is 18.9\% for the lighter and 16.4\% for the heavier.
Therefore, the effect of the treatment is -2.5\%.
In this dataset, there are 40 pre-treatment co-variants evaluating the pregnancy of the twins, such as the pregnancy
weeks, quality of care during gestation, alcohol consumption and tobacco usage during pregnancy nutrition status of
their mother etc.
In the Twins dataset, both the lighter(control outcome) and the heavier(treatment outcome) infant are being observed.
To simulate the selection biases, users have to deploy their own treatment assignment.
For example, in the original paper\cite{louizos2017causal}, a bias was created following equation~\eqref{eq:eq1}
\begin{equation}
    \begin{split}
        W_i\mathbf{X}_i\sim Bern(Sigmod(\mathbf{w'}\mathbf{X}_i)+n)\\
        \mathbf{w}\sim U(-0.1, 0.1)^{40\times 1}\\
        n\sim \mathbf{N}(0, 0.1))
    \end{split}
    \label{eq:eq1}
\end{equation}

\subsubsection{Jobs}.
The Jobs dataset is a combination of Lalonde experiment\cite{lalonde1986evaluating} and the PSID comparison group.
Lalonde's study inspected the effect of a job training program (the treatment) on the participant's earnings, after
years of the completion of the training.
The pre-treatment data consists of a number of variables, including the participants' age, race, academic achieves and
their earnings before the training.
The outcome is their job status.
This dataset can be downloaded from the website http://users.nber.org/~rdehejia/data/nswdata2.html

\subsubsection{ACIC 2016-2019}.
This is a series of datasets published by the Atlantic Causal Inference Conference committee while they're holding the
causal inference data analysis challenge.
These datasets focused on various causal inference problems and the details are as follows.

\textbf{ACIC 2016}.
ACIC 2016 Challenge focused on which approaches to causal inference perform well in particular observational study
settings.
The committee provided 77 datasets with different degrees of non-linearity, sparsity and overlapping between treatment
and outcome.
The pre-treatment data is extracted from the Infant Health and Development Program containing 58 variables, and the
outcomes, both factual and counter-factual, are generated by simulation.
The selection bias is created by only keeping children with white moms.
The result of the 2016 competition is summarized in~\cite{dorie2019automated}, and the dataset can be found in
https://drive.google.com/"le/d/0B7pG5PPgj6A3N09ibmFwNWE1djA/view

\textbf{ACIC 2017}.
The theme of ACIC 2017 Challenge is exploring the estimation and inference for conditional average treatment effects
(CATE) with targeted selection.
The meaning of targeted selection is the likelihood of treatment that the individual received is a function of the
individual's expected response while untreated.
This selection will lead to strong confounding\cite{hahn2019atlantic}.
The pre-treatment data is extracted from the Infant Health and Development Program as well, but with only 8 variables.
The outcomes and treatment are synthesized following 32 fixed data generating process with four types of errors.
250 independent replica were produced during each of the generating process, so there are 8,000 dataset in total.

\textbf{ACIC 2018}.
The ACIC 2018 Challenge consists of two sub-challenge focusing on censoring and scaling.
Censoring means not all the sample in the dataset has observed outcome, which means the dataset used for the censoring
sub-challenge contains samples without outcomes, or only part of the outcomes.
The goal of the scaling sub-challenge is to understand how run-time and memory requirements of the applied causal
methods scale, as datasets get larger, and to understand which methods benefit from additional data and which do not.
The datasets can be downloaded from https://www.synapse.org/\#!Synapse:syn11294478/wiki/486304.

\textbf{ACIC 2019}.
The goal of this chanllenge is to estimate the low and high dimension quasi-real-world dataset.
The samples in these datasets have different pre-treatment and outcome dimensions, and the data generation code is
available on Google Drive\footnote{https://drive.google.com/file/d/1Qqgmb3R9Vt9KTx6t8i\_5IbFenylsPfrK/view}.

\subsection{Codes and Tool Packages}\label{subsec:codes-and-tool-packages}

In this section, we introduce some tool packages for causal inference, including Dowhy\cite{sharma2020dowhy}, CausalML
and EconML\cite{bach2022doubleml}, and they're detailed below.

\textbf{Dowhy}\footnote{https://github.com/py-why/dowhy}: Dowhy is an end-to-end python library for causal inference
published by Microsoft.
It provides a principled four-step interface for causal inference.
It supports the estimation of causal effect with various identification methods, including front door, back door,
instrumental variable and so on.
Methods it implemented include Propensity-based Stratification, PSM, IPW and Regression.

\textbf{CausalML}\footnote{https://github.com/uber/causalml}: CausalML is a python Uber published library for uplift
modeling and Causal Inference with machine learning(ML).
It provides a set of uplift modeling and causal inference methods using ML algorithms based on recent research.
It now supports several tree-based algorithms, meta-learner algorithms, instrumental variables algorithms, and neural-
network-based algorithms.

\textbf{EconML}\footnote{https://github.com/microsoft/EconML#blogs-and-publications}: EconML is a python package for ML-
based heterogeneous treatment effects estimation.
It is provided by Microsoft as part of the ALICE project.
It implemented some recent state-of-the-art techniques in the literature at machine learning.
It supports Doubly Robust Learner, Orthogonal Random Forests, Meta-Learners, Deep Instrumental Variables etc.


